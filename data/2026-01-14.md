<div id=toc></div>

# Table of Contents

- [q-bio.PE](#q-bio.PE) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 4]


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [1] [Tara Polaris expeditions: Sustained decadal observations of the coupled Arctic system in rapid transition](https://arxiv.org/abs/2601.08370)
*Mathieu Ardyna,Marcel Nicolaus,Marie-Noëlle Houssais,Jean-Christophe Raut,Hélène Angot,Kelsey Bisson,Kristina A Brown,J Michel Flores,Pierre E Galand,Jean-François Ghiglione,Kathy S Law,François Ravetta,Julia Schmale,Jeroen E Sonke,Marcel Babin,Maxime Geoffroy,Lars-Eric Heimbürger-Boavida,Connie Lovejoy,Søren Rysgaard,Nina Schuback,Martin Vancoppenolle,Jean-Eric Tremblay,Chris Bowler,Lee Karp-Boss,Romain Troublé*

Main category: q-bio.PE

TL;DR: Tara Polaris计划：2026-2046年在中央北冰洋进行的20年多学科漂流观测项目，旨在监测北极系统快速转变，区分长期趋势与季节/年际变化


<details>
  <summary>Details</summary>
Motivation: 北极系统正在快速转变，预计本世纪中叶前夏季将出现无冰海洋，北极将更受中纬度过程影响，污染物和新物种增加。需要系统监测所有关键指标以理解系统、改进预测并支持基于知识的决策。

Method: 在Tara极地站实施持续多十年观测计划（2026-2046年），设计为一系列全年漂流考察（Tara Polaris），覆盖中央北冰洋所有季节。采用一致方法收集多学科数据，涵盖大气、海冰和海洋的生态、地球化学、生物和物理参数与过程。

Result: 该计划将能够区分长期趋势与季节和年际变化，理解并量化耦合北极系统的主要反馈机制，包括其季节和年际趋势以及空间变异性。

Conclusion: Tara Polaris计划通过20年持续观测，将为理解北极系统转变提供关键数据，支持预测和决策制定，应对北极快速变化带来的挑战。

Abstract: The coupled Arctic system is in rapid transition and is set to undergo further dramatic changes over the coming decades. These changes will lead most likely to an ice-free ocean in summer, expected before mid-century. The Arctic will become more strongly influenced by atmospheric and oceanographic processes characteristic of mid-latitudes, increasing the prevalence of contaminants and new biological species. This ongoing transition of the Arctic to a new state necessitates systematic monitoring of all sentinels (variables that make an essential contribution to characterizing the Earth's state) to improve our understanding of the system, enhance forecasting and support knowledge-based decisions. Here, we describe a sustained multi-decadal observation program to be implemented on the Tara Polar Station between 2026 and 2046. The monitoring program is designed as a series of year-long drift expeditions, called Tara Polaris, in the central Arctic Ocean, covering all seasons. The multidisciplinary data will bridge ecological, geochemical, biological, and physical parameters and processes in the atmosphere, sea ice and ocean. In addition, data collected with consistent methodologies over a 20-year period will make it possible to distinguish long-term trends from seasonal and interannual variability. In this paper, we discuss specific measurement challenges in each compartment (i.e., atmosphere, sea ice and ocean) along key sentinels and the most pressing scientific questions to be addressed. The expected outcomes of the Tara Polaris program will enable us to understand and quantify the main feedbacks of the coupled Arctic system, with their seasonal and interannual trends and spatial variability.

</details>


### [2] [Beta-coalescents when sample size is large](https://arxiv.org/abs/2601.08538)
*Jonathan A Chetwynd-Diggle,Bjarki Eldon*

Main category: q-bio.PE

TL;DR: 论文提出了一种扩展的扫奖繁殖模型，该模型结合了潜在后代数量的上限，并展示了不同上限条件下会得到Kingman合并、不完全Beta合并或完整Beta合并过程。


<details>
  <summary>Details</summary>
Motivation: 研究扫奖繁殖（个体繁殖成功高度偏斜）在广播产卵种群中的数学建模，为Wright-Fisher模型提供替代方案，并探讨生物学上合理的潜在后代数量上限对合并过程的影响。

Method: 扩展单倍体随机交配种群的扫奖繁殖模型，引入个体潜在后代数量的上限，通过理论分析和模拟研究不同上限条件（如N/log N）下的合并过程收敛性。

Result: 根据上限相对于种群大小的行为，模型可产生Kingman合并、不完全Beta合并或完整Beta合并；收敛可能较慢，小样本量可能使收敛无效；Beta合并极限下位点频率谱与极限树预测一致。

Conclusion: 引入潜在后代数量上限是生物学合理的，模型提供了扫奖繁殖的数学框架，揭示了不同合并过程的出现条件，对种群遗传学中的样本量选择和推断具有重要意义。

Abstract: Sweepstakes reproduction refers to a highly skewed individual recruitment success without involving natural selection and may apply to individuals in broadcast spawning populations characterised by Type III survivorship. We consider an extension of the model of sweepstakes reproduction for a haploid panmictic population of constant size $N$; the extension also works as an alternative to the Wright-Fisher model. Our model incorporates an upper bound on the random number of potential offspring (juveniles) produced by a given individual. Depending on how the bound behaves relative to the total population size, we obtain the Kingman coalescent, an incomplete Beta-coalescent, or the (complete) Beta-coalescent. We argue that applying such an upper bound is biologically reasonable. Moreover, we estimate the error of the coalescent approximation. The error estimates reveal that convergence can be slow, and small sample size can be sufficient to invalidate convergence, for example if the stated bound is of the form $N/\log N$. We use simulations to investigate the effect of increasing sample size on the site-frequency spectrum. When the limit is a Beta-coalescent, the site frequency spectrum will be as predicted by the limiting tree even though the full coalescent tree may deviate from the limiting one. When in the domain of attraction of the Kingman coalescent the effect of increasing sample size depends on the effective population size as has been noted in the case of the Wright-Fisher model. Conditioning on the population ancestry (the random ancestral relations of the entire population at all times) may have little effect on the site-frequency spectrum for the models considered here (as evidenced by simulation results).

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [3] [From local defects to shear-organized biofilms in tonsillar crypts via computational simulations](https://arxiv.org/abs/2601.07863)
*Arturo Tozzi*

Main category: q-bio.QM

TL;DR: 该研究提出了一个生物物理框架来解释扁桃体隐窝中生物膜的长期持久性和间歇性扩散现象，将这一过程建模为两种机械现象相互作用的结果：Kosterlitz-Thouless型缺陷成核过程和Kelvin-Helmholtz型剪切驱动界面不稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前生化和微生物学描述无法完全解释扁桃体隐窝中生物膜的长期持久性和间歇性扩散现象，特别是在空间定位方面。需要新的理论框架来理解这一复杂的生物物理过程。

Method: 引入一个生物物理框架，将隐窝几何建模为受限的异质环境，促进由生长诱导压缩产生的机械持久性表面缺陷。将呼吸和吞咽相关的切向剪切作为选择性放大这些缺陷的机制，产生有组织的表面变形。通过数值模拟验证理论框架。

Result: 数值模拟显示，只有当两种机制（缺陷成核和剪切驱动不稳定性）共存时，才能产生局部化、传播性和持久性的界面结构。缺乏任一机制都会导致扩散的、非结构化的动力学行为。

Conclusion: 扁桃体生物膜动力学源于两种机械现象的相互作用：Kosterlitz-Thouless型缺陷成核过程和Kelvin-Helmholtz型剪切驱动界面不稳定性。这一框架为理解生物膜在复杂环境中的持久性和空间组织提供了新的理论视角。

Abstract: Biofilms in human tonsillar crypts show long term persistence with episodic dispersal that current biochemical and microbiological descriptions do not fully explain, particularly with respect to spatial localization. We introduce a biophysical framework in which tonsillar biofilm dynamics arise from the interaction between two mechanical phenomena: a Kosterlitz Thouless type defect nucleation process and a Kelvin Helmholtz type shear driven interfacial instability. Crypt geometry is modeled as a confined, heterogeneous environment that promotes mechanically persistent surface defects generated by growth induced compression. Tangential shear associated with breathing and swallowing selectively amplifies these defects, producing organized surface deformations. Numerical simulations show that only the coexistence of both mechanisms yields localized, propagating, and persistent interface structures, whereas their absence leads to diffuse, unstructured dynamics.

</details>


### [4] [Imaging-anchored Multiomics in Cardiovascular Disease: Integrating Cardiac Imaging, Bulk, Single-cell, and Spatial Transcriptomics](https://arxiv.org/abs/2601.07871)
*Minh H. N. Le,Tuan Vinh,Thanh-Huy Nguyen,Tao Li,Bao Quang Gia Le,Han H. Huynh,Monika Raj,Carl Yang,Min Xu,Nguyen Quoc Khanh Le*

Main category: q-bio.QM

TL;DR: 这篇综述探讨了将心脏影像表型与转录组学和空间分子状态连接起来的联合表征方法，旨在整合心血管疾病的多模态数据以实现更好的临床转化。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病源于遗传风险、分子程序和组级重塑之间的相互作用，目前医疗系统产生了大量心脏影像和转录组学数据，但这些数据仍在分离的流程中分析，缺乏整合。

Method: 采用影像锚定视角，将超声心动图、心脏MRI和CT定义为心脏的空间表型，结合bulk、单细胞和空间转录组学提供细胞类型和位置特异性分子背景。综述了多模态融合方法，特别关注处理缺失数据、有限样本量和批次效应。

Result: 讨论了放射基因组学、空间分子对齐和基于影像的基因表达预测的整合流程，分析了常见失败模式、实际考虑因素和开放挑战。

Conclusion: 人类心肌和动脉粥样硬化斑块的空间多组学、单细胞和空间基础模型以及多模态医学基础模型正在共同推动影像锚定的多组学方法向大规模心血管转化迈进。

Abstract: Cardiovascular disease arises from interactions between inherited risk, molecular programmes, and tissue-scale remodelling that are observed clinically through imaging. Health systems now routinely generate large volumes of cardiac MRI, CT and echocardiography together with bulk, single-cell and spatial transcriptomics, yet these data are still analysed in separate pipelines. This review examines joint representations that link cardiac imaging phenotypes to transcriptomic and spatially resolved molecular states. An imaging-anchored perspective is adopted in which echocardiography, cardiac MRI and CT define a spatial phenotype of the heart, and bulk, single-cell and spatial transcriptomics provide cell-type- and location-specific molecular context. The biological and technical characteristics of these modalities are first summarised, and representation-learning strategies for each are outlined. Multimodal fusion approaches are reviewed, with emphasis on handling missing data, limited sample size, and batch effects. Finally, integrative pipelines for radiogenomics, spatial molecular alignment, and image-based prediction of gene expression are discussed, together with common failure modes, practical considerations, and open challenges. Spatial multiomics of human myocardium and atherosclerotic plaque, single-cell and spatial foundation models, and multimodal medical foundation models are collectively bringing imaging-anchored multiomics closer to large-scale cardiovascular translation.

</details>


### [5] [An open-source computational framework for immersed fluid-structure interaction modeling using FEBio and MFEM](https://arxiv.org/abs/2601.08266)
*Ryan T. Black,Steve A. Maas,Wensi Wu,Jalaj Maheshwari,Tzanio Kolev,Jeffrey A. Weiss,Matthew A. Jolley*

Main category: q-bio.QM

TL;DR: 提出了一种新型开源浸入式流固耦合框架，通过耦合MFEM和FEBio两个成熟的有限元库，解决了生物系统（如心脏瓣膜）大变形和接触力学模拟中的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 生物系统的流固耦合模拟面临重大计算挑战，特别是涉及大结构变形和接触力学（如心脏瓣膜动力学）的应用。传统的ALE方法因网格畸变而遇到根本性困难，这促使了浸入式技术的发展。

Method: 开发了一个开源浸入式流固耦合框架，战略性地耦合了两个成熟的有限元库：MFEM（GPU就绪、可扩展的并行计算库）和FEBio（针对生物力学应用的非线性有限元求解器）。采用虚拟域方法结合变分多尺度稳定化，使用完全隐式、单块方案实现强耦合。

Result: 该框架创建了独特的协同效应：流体求解器利用MFEM的分布式内存并行化和GPU加速路径，而浸入式固体则利用FEBio全面的超弹性和粘弹性本构模型。通过多个测试问题（包括3D半月形心脏瓣膜模拟）展示了框架的能力。

Conclusion: 该平台满足了将先进生物力学建模与高性能计算基础设施相结合的开源浸入式流固耦合软件的迫切需求，其模块化架构便于扩展到额外的物理和元素技术。

Abstract: Fluid-structure interaction (FSI) simulation of biological systems presents significant computational challenges, particularly for applications involving large structural deformations and contact mechanics, such as heart valve dynamics. Traditional ALE methods encounter fundamental difficulties with such problems due to mesh distortion, motivating immersed techniques. This work presents a novel open-source immersed FSI framework that strategically couples two mature finite element libraries: MFEM, a GPU-ready and scalable library with state-of-the-art parallel performance developed at Lawrence Livermore National Laboratory, and FEBio, a nonlinear finite element solver with sophisticated solid mechanics capabilities designed for biomechanics applications developed at the University of Utah. This coupling creates a unique synergy wherein the fluid solver leverages MFEM's distributed-memory parallelization and pathway to GPU acceleration, while the immersed solid exploits FEBio's comprehensive suite of hyperelastic and viscoelastic constitutive models and advanced solid mechanics modeling targeted for biomechanics applications. FSI coupling is achieved using a fictitious domain methodology with variational multiscale stabilization for enhanced accuracy on under-resolved grids expected with unfitted meshes used in immersed FSI. A fully implicit, monolithic scheme provides robust coupling for strongly coupled FSI characteristic of cardiovascular applications. The framework's modular architecture facilitates straightforward extension to additional physics and element technologies. Several test problems are considered to demonstrate the capabilities of the proposed framework, including a 3D semilunar heart valve simulation. This platform addresses a critical need for open-source immersed FSI software combining advanced biomechanics modeling with high-performance computing infrastructure.

</details>


### [6] [Automated Lesion Segmentation of Stroke MRI Using nnU-Net: A Comprehensive External Validation Across Acute and Chronic Lesions](https://arxiv.org/abs/2601.08701)
*Tammar Truzman,Matthew A. Lambon Ralph,Ajay D. Halai*

Main category: q-bio.QM

TL;DR: 本研究系统评估了nnU-Net框架在多个公开MRI数据集上的脑卒中病灶分割性能，发现模型在不同卒中阶段、成像模态和数据集间具有良好泛化能力，性能接近人工标注者间一致性，并识别了影响泛化能力的关键因素。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在脑卒中病灶分割方面虽然有所改进，但多数模型针对特定成像环境优化，在独立数据集、不同模态和卒中阶段间泛化能力较差。需要系统评估自动分割模型的泛化性能，以推动临床研究、预后建模和个性化干预的发展。

Method: 使用nnU-Net框架在多个公开的异质性MRI数据集上进行系统评估，涵盖急性和慢性卒中阶段。模型在DWI、FLAIR和T1加权MRI上进行训练和测试，并在独立数据集上评估。分析不同成像模态、训练数据特征、病灶体积和图像质量对泛化能力的影响。

Result: 模型在不同卒中阶段表现出稳健的泛化能力，分割准确度接近报道的人工标注者间可靠性。急性卒中中，DWI训练模型始终优于FLAIR模型，多模态组合仅带来适度提升。慢性卒中中，增加训练集规模可提高性能，但超过数百例后收益递减。病灶体积是准确度的关键决定因素，小病灶更难分割。图像质量显著影响泛化性，高质量数据训练的模型能良好泛化到噪声图像。

Conclusion: 自动病灶分割能够接近人类水平性能，同时识别了影响泛化能力的关键因素（包括成像模态、训练数据特征、病灶体积和图像质量），这些发现为开发更稳健的病灶分割工具提供了重要指导。

Abstract: Accurate and generalisable segmentation of stroke lesions from magnetic resonance imaging (MRI) is essential for advancing clinical research, prognostic modelling, and personalised interventions. Although deep learning has improved automated lesion delineation, many existing models are optimised for narrow imaging contexts and generalise poorly to independent datasets, modalities, and stroke stages. Here, we systematically evaluated stroke lesion segmentation using the nnU-Net framework across multiple heterogeneous, publicly available MRI datasets spanning acute and chronic stroke. Models were trained and tested on diffusion-weighted imaging (DWI), fluid-attenuated inversion recovery (FLAIR), and T1-weighted MRI, and evaluated on independent datasets. Across stroke stages, models showed robust generalisation, with segmentation accuracy approaching reported inter-rater reliability. Performance varied with imaging modality and training data characteristics. In acute stroke, DWI-trained models consistently outperformed FLAIR-based models, with only modest gains from multimodal combinations. In chronic stroke, increasing training set size improved performance, with diminishing returns beyond several hundred cases. Lesion volume was a key determinant of accuracy: smaller lesions were harder to segment, and models trained on restricted volume ranges generalised poorly. MRI image quality further constrained generalisability: models trained on lower-quality scans transferred poorly, whereas those trained on higher-quality data generalised well to noisier images. Discrepancies between predictions and reference masks were often attributable to limitations in manual annotations. Together, these findings show that automated lesion segmentation can approach human-level performance while identifying key factors governing generalisability and informing the development of lesion segmentation tools.

</details>
