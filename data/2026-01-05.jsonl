{"id": "2601.00030", "categories": ["q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.00030", "abs": "https://arxiv.org/abs/2601.00030", "authors": ["A. Murat Maga", "Steve Pieper", "Cassandra Donatelli", "Paul M Gignac", "Matthew Kolmann", "Christopher Noto", "Adam Summers", "Natalie Taft"], "title": "Forking Anatomy: How MorphoDepot Applies the Open-Source Development Model to 3D Digital Morphology", "comment": "20 pages, 1 table and 2 figures", "summary": "The increasing use of 3D imaging technologies in biological sciences is generating vast repositories of anatomical data, yet significant barriers prevent this data from reaching its full potential in educational and collaborative contexts. While sharing raw CT and MRI scans has become routine, distributing value-added segmented datasets, where anatomical structures are precisely labeled and delineated, remains difficult and rare. Current repositories function primarily as static archives, lacking mechanisms for iterative refinement, community-driven curation, standardized orientation protocols, and the controlled terminology essential for downstream computational applications, including artificial intelligence, to help us analyze and interpret these unprecedented data resources.\n  We introduce MorphoDepot, a framework that adapts the \"fork-and-contribute\" model, a cornerstone of modern open-source software development, for collaborative management of 3D morphological data. By integrating git version control and GitHub's \"social\" collaborative infrastructure with 3D Slicer and its SlicerMorph extension, MorphoDepot transforms segmented anatomical datasets from static resources into dynamic, community-curated projects. This approach directly addresses the challenges of distributed collaboration, enforces transparent provenance tracking, and creates high-quality, standardized training data for AI model development. The result is a system that embodies FAIR (Findable, Accessible, Interoperable, and Reusable) data principles while creating powerful new opportunities for remote learning and collaborative science for biological sciences in general and evolutionary morphology in particular."}
{"id": "2601.00050", "categories": ["q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.00050", "abs": "https://arxiv.org/abs/2601.00050", "authors": ["Sam Victor"], "title": "Domain-aware priors enable vertical federated learning in data-scarce coral multi-omics", "comment": "19 pages, 06 figures, 01 tables, 21 references. Journal submission currently in progress", "summary": "Vertical federated learning enables multi-laboratory collaboration on distributed multi-omics datasets without sharing raw data, but exhibits severe instability under extreme data scarcity (P much greater than N) when applied generically. Here, we investigate how domain-aware design choices, specifically gradient saliency guided feature selection with biologically motivated priors, affect the stability and interpretability of VFL architectures in small-sample coral stress classification (N = 13 samples, P = 90579 features across transcriptomics, proteomics, metabolomics, and microbiome data).\n  We benchmark a domain-aware VFL framework against two baselines on the Montipora capitata thermal stress dataset: (i) a standard NVFlare-based VFL and (ii) LASER, a label-aware VFL method. Domain-aware VFL achieves an AUROC of 0.833 plus or minus 0.030 after reducing dimensionality by 98.6 percent, significantly outperforming NVFlare VFL, which performs at chance level (AUROC 0.500 plus or minus 0.125, p = 0.0058). LASER shows modest improvement (AUROC 0.600 plus or minus 0.215) but exhibits higher variance and does not reach statistical significance.\n  Domain-aware feature selection yields stable top-feature sets across analysis parameters. Negative control experiments using permuted labels produce AUROC values below chance (0.262), confirming the absence of data leakage and indicating that observed performance arises from genuine biological signal. These results motivate design principles for VFL in extreme P much greater than N regimes, emphasizing domain-informed dimensionality reduction and stability-focused evaluation."}
{"id": "2601.00073", "categories": ["q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.00073", "abs": "https://arxiv.org/abs/2601.00073", "authors": ["Md Anisur Rahman", "Md Asif Hasan Khan", "Tuan Mai", "Jinki Kim"], "title": "Non-Contact and Non-Destructive Detection of Structural Defects in Bioprinted Constructs Using Video-Based Vibration Analysis", "comment": null, "summary": "Bioprinting technology has advanced significantly in the fabrication of tissue-like constructs with complex geometries for regenerative medicine. However, maintaining the structural integrity of bioprinted materials remains a major challenge, primarily due to the frequent and unexpected formation of hidden defects. Traditional defect detection methods often require physical contact that may not be suitable for hydrogel-based biomaterials due to their inherently soft nature, making non-invasive and straightforward structural evaluation necessary in this field. To advance the state of the art, this study presents a novel non-contact method for non-destructively detecting structural defects in bioprinted constructs using video-based vibration analysis. Ear-shaped constructs were fabricated using a bioink composed of sodium alginate and \\k{appa}-carrageenan using extrusion-based bioprinting. To simulate printing defects, controlled geometric, interlayer, and pressure-induced defects were systematically introduced into the samples. The dynamic response of each structure was recorded using a high-speed camera and analyzed via phase-based motion estimation techniques. Experimental results demonstrate that all defective samples exhibit consistent changes in the dynamic characteristics compared to baseline samples, with increasingly pronounced deviation observed as defect severity increases, which reflect changes in effective stiffness and mass distribution induced by internal anomalies, even when such defects are not detectable through surface inspection. The experimental trends were also validated through finite element simulations. Overall, this work demonstrates that video-based vibrometry is a powerful approach for assessing the quality of bioprinted constructs, offering a practical pathway toward robust structural health monitoring in next-generation bio-additive manufacturing workflows."}
{"id": "2601.00277", "categories": ["q-bio.QM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00277", "abs": "https://arxiv.org/abs/2601.00277", "authors": ["Ali Anaissi", "Seid Miad Zandavi", "Weidong Huang", "Junaid Akram", "Basem Suleiman", "Ali Braytee", "Jie Hua"], "title": "Benchmarking Preprocessing and Integration Methods in Single-Cell Genomics", "comment": "The 23rd Australasian Data Science and Machine Learning Conference (AusDM'25)", "summary": "Single-cell data analysis has the potential to revolutionize personalized medicine by characterizing disease-associated molecular changes at the single-cell level. Advanced single-cell multimodal assays can now simultaneously measure various molecules (e.g., DNA, RNA, Protein) across hundreds of thousands of individual cells, providing a comprehensive molecular readout. A significant analytical challenge is integrating single-cell measurements across different modalities. Various methods have been developed to address this challenge, but there has been no systematic evaluation of these techniques with different preprocessing strategies. This study examines a general pipeline for single-cell data analysis, which includes normalization, data integration, and dimensionality reduction. The performance of different algorithm combinations often depends on the dataset sizes and characteristics. We evaluate six datasets across diverse modalities, tissues, and organisms using three metrics: Silhouette Coefficient Score, Adjusted Rand Index, and Calinski-Harabasz Index. Our experiments involve combinations of seven normalization methods, four dimensional reduction methods, and five integration methods. The results show that Seurat and Harmony excel in data integration, with Harmony being more time-efficient, especially for large datasets. UMAP is the most compatible dimensionality reduction method with the integration techniques, and the choice of normalization method varies depending on the integration method used."}
{"id": "2601.00757", "categories": ["q-bio.PE", "cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.00757", "abs": "https://arxiv.org/abs/2601.00757", "authors": ["Wenjie Zhang", "Yusheng Li", "Qin Li", "Guojun Huang", "Minyu Feng"], "title": "Modeling Epidemic Dynamics of Mutant Strains with Evolutionary Game-based Vaccination Behavior", "comment": null, "summary": "The outbreak of mutant strains and vaccination behaviors have been the focus of recent epidemiological research, but most existing epidemic models failed to simultaneously capture viral mutation and consider the complexity and behavioral dynamics of vaccination. To address this gap, we develop an extended SIRS model that distinguishes infections with the original strain and a mutant strain, and explicitly introduces a vaccinated compartment state. At the behavioral level, we employ evolutionary game theory to model individual vaccination decisions, where strategies are determined by both neighbors' choices and the current epidemiological situation. This process corresponds to the time-varying vaccination rate of susceptible individuals transitioning to vaccinated individuals at the epidemic spreading level. We then couple the epidemic and vaccination behavioral processes through the microscopic Markov chain approach (MMCA) and finally investigate the evolutionary dynamics via numerical simulations. The results show that our framework can effectively mitigate outbreaks across different disease scenarios. Sensitivity analysis further reveals that vaccination uptake is most strongly influenced by vaccine cost, efficacy, and perceived risk of side effects. Overall, this behavior-aware modeling framework captures the co-evolution of viral mutation and vaccination behavior, providing quantitative and theoretical support for designing effective public health vaccination policies."}
{"id": "2601.00608", "categories": ["q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.00608", "abs": "https://arxiv.org/abs/2601.00608", "authors": ["Clara Bender", "Line Davidsen", "Søren Schou Olesen", "Simon Lebech Cichosz"], "title": "Peak-Nadir Encoding for Efficient CGM Data Compression and High-Fidelity Reconstruction", "comment": null, "summary": "Aim/background: Continuous glucose monitoring (CGM) generates dense time-series data, posing challenges for efficient storage, transmission, and analysis. This study evaluates novel encoding strategies that reduce CGM profiles to a compact set of landmark points while maintaining fidelity in reconstructed signals and derived glycemic metrics.\n  Methods: We utilized two complementary CGM datasets, synthetic data generated via a Conditional Generative Adversarial Network (CGAN) and real-world measurements from a randomized crossover trial, to develop and validate three encoding approaches: (1) Peaks & Nadirs (PN), (2) Peaks, Nadirs, and Support Points (PN+), and (3) Uniform Downsampling. Each method compresses CGM profiles by selecting key timestamps and glucose values, followed by signal reconstruction via interpolation. Performance was assessed using compression ratio, mean absolute error (MAE), and R^2 between original and reconstructed clinically relevant CGM-derived metrics. Statistical analyses evaluated the preservation of clinically relevant glucose features.\n  Results: Across varying compression settings, PN+ consistently outperformed PN and downsampling, achieving the highest R^2 and lowest MAE. At a compression ratio of 13 (22 landmark points per 24-hour profile), PN+ reduced MAE by a factor of 3.6 compared to downsampling (0.77 vs. 2.75), with notable improvements in metrics sensitive to glucose excursions. Encoding and decoding required an average of 0.13 seconds per profile. Validation on real-world data confirmed these trends.\n  Conclusions: The proposed PN+ method produces a compact CGM representation that retains critical glycemic dynamics while discarding redundant portions of the profiles. The CGM signal can be reconstructed with high precision from the encoding representation."}
{"id": "2601.00769", "categories": ["q-bio.PE", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.00769", "abs": "https://arxiv.org/abs/2601.00769", "authors": ["Deeptanshu Pandey", "Dwipanjan Sanyal", "Vladimir N. Uversky", "Daniel C. Zielinski", "Sourav Chowdhury"], "title": "Evolutionary and Structural Constraints Define a Mutation-Resistant Catalytic Core in E. coli Serine Hydroxy methyltransferase (SHMT)", "comment": "50 pages 6 figures", "summary": "Serine hydroxymethyltransferase is an essential enzyme in the Escherichia coli folate pathway, yet it has not been adopted as an antibacterial target, unlike DHFR, DHPS, or thymidylate synthase. To investigate this discrepancy, we applied a multi-scale computational framework that integrates large-scale sequence analysis of 1000 homologs, coevolutionary interaction mapping, structural community analysis, intrinsic disorder profiling, and adaptive fitness modelling. These analyses converge on a single conclusion: the catalytic core of SHMT forms an exceptionally conserved and tightly coupled structural unit. This region exhibits dense coevolution, strong intramolecular connectivity, minimal disorder, and extremely low mutational tolerance. Peripheral loops and termini, in contrast, are far more flexible. Relative to established folate-pathway antibiotic targets, SHMT active site is even more rigid and evolutionarily constrained. This extreme constraint may limit the emergence of resistance-compatible mutations, providing a plausible explanation for the absence of natural-product inhibitors. Fitness trajectory modelling supports this interpretation, showing that nearly all active-site residues tolerate only rare or neutral substitutions. Together, these findings identify SHMT as a structurally stable and evolutionarily restricted enzyme whose catalytic architecture is unusually protected. This makes SHMT an underexplored yet promising target for the rational design of next-generation antibacterial agents."}
{"id": "2601.00618", "categories": ["q-bio.QM", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.00618", "abs": "https://arxiv.org/abs/2601.00618", "authors": ["Vasiliki Tsampazi", "Nicholas M. Glykos"], "title": "Quantifying the uncertainty of molecular dynamics simulations : Good-Turing statistics revisited", "comment": null, "summary": "We have previously shown that Good-Turing statistics can be applied to molecular dynamics trajectories to estimate the probability of observing completely new (thus far unobserved) biomolecular structures, and showed that the method is stable, dependable and its predictions verifiable. The major problem with that initial algorithm was the requirement for calculating and storing in memory the two-dimensional RMSD matrix of the currently available trajectory. This requirement precluded the application of the method to very long simulations. Here we describe a new variant of the Good-Turing algorithm whose memory requirements scale linearly with the number of structures in the trajectory, making it suitable even for extremely long simulations. We show that the new method gives essentially identical results with the older implementation, and present results obtained from trajectories containing up to 22 million structures. A computer program implementing the new algorithm is available from standard repositories."}
{"id": "2601.00656", "categories": ["q-bio.QM", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.00656", "abs": "https://arxiv.org/abs/2601.00656", "authors": ["Biraja Ghoshal"], "title": "Quantum Simulation of Protein Fragment Electronic Structure Using Moment-based Adaptive Variational Quantum Algorithms", "comment": "Keywords: quantum computing, variational quantum eigensolver, protein fragments, electronic structure, drug discovery, enzyme engineering", "summary": "Background: Understanding electronic interactions in protein active sites is fundamental to drug discovery and enzyme engineering, but remains computationally challenging due to exponential scaling of quantum mechanical calculations.\n  Results: We present a quantum-classical hybrid framework for simulating protein fragment electronic structure using variational quantum algorithms. We construct fermionic Hamiltonians from experimentally determined protein structures, map them to qubits via Jordan-Wigner transformation, and optimize ground state energies using the Variational Quantum Eigensolver implemented in pure Python. For a 4-orbital serine protease fragment, we achieve chemical accuracy (< 1.6 mHartree) with 95.3% correlation energy recovery. Systematic analysis reveals three-phase convergence behaviour with exponential decay (α = 0.95), power law optimization (γ = 1.21), and asymptotic approach. Application to SARS-CoV-2 protease inhibition demonstrates predictive accuracy (MAE=0.25 kcal/mol), while cytochrome P450 metabolism predictions achieve 85% site accuracy.\n  Conclusions: This work establishes a pathway for quantum-enhanced biomolecular simulations on near-term quantum hardware, bridging quantum algorithm development with practical biological applications."}
