{"id": "2602.03228", "categories": ["q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.03228", "abs": "https://arxiv.org/abs/2602.03228", "authors": ["Ryo Oizumi", "Kensaku Kinjo", "Yuki Chino"], "title": "Asymptotic Behavior of Integral Projection Models via Genealogical Quantities", "comment": "30 pages", "summary": "Multi-state structured population models, including integral projection models (IPMs) and age-structured McKendrick equations, link individual life histories to population growth and composition, yet the demographic meaning of their dominant eigenstructure can be difficult to interpret. A main goal of this paper is to derive interpretable demographic indicators for multi-state heterogeneity -- in particular expected generation numbers, which act as an effective genealogical memory length (in generations) of the ancestry-weighted contributions driving growth -- together with type reproduction numbers and generation intervals, directly from life-history transition kernels.\n  To this end we develop a determinant-free genealogical framework based on a reference-point operator, a rank-one construction at the kernel level that singles out a biologically chosen reference state and organizes lineages by their contributions relative to that state. This yields stable distributions and reproductive values as convergent series of iterated kernels, and leads to an Euler--Lotka-like characteristic equation expressed by reference-point moments. The resulting expansion admits a closed combinatorial form via ordinary partial Bell polynomials, providing a direct bridge from transition kernels to genealogical quantities.\n  We extend the approach to multi-state McKendrick equations and show how these indicators quantify how population scale and composition are determined by ancestry-weighted initial-state information. The framework avoids restrictive Hilbert--Schmidt assumptions and clarifies how temporal memory and multi-type heterogeneity emerge from cross-generational accumulation, yielding a unified and interpretable route from transition kernels to multi-state demographic indicators."}
{"id": "2602.03824", "categories": ["q-bio.PE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03824", "abs": "https://arxiv.org/abs/2602.03824", "authors": ["Jiao Sun"], "title": "Deep-learning-based pan-phenomic data reveals the explosive evolution of avian visual disparity", "comment": "Readers from the field of computer science may be interested in section 2.1, 2.2, 3.1, 4.1, 4.2. These sections discussed the interpretability and representation learning, especially the texture vs shape problem, highlighting our model's ability of overcoming the texture biases and capturing overall shape features. (Although they're put here to prove the biological validity of the model.)", "summary": "The evolution of biological morphology is critical for understanding the diversity of the natural world, yet traditional analyses often involve subjective biases in the selection and coding of morphological traits. This study employs deep learning techniques, utilising a ResNet34 model capable of recognising over 10,000 bird species, to explore avian morphological evolution. We extract weights from the model's final fully connected (fc) layer and investigate the semantic alignment between the high-dimensional embedding space learned by the model and biological phenotypes. The results demonstrate that the high-dimensional embedding space encodes phenotypic convergence. Subsequently, we assess the morphological disparity among various taxa and evaluate the association between morphological disparity and species richness, demonstrating that species richness is the primary driver of morphospace expansion. Moreover, the disparity-through-time analysis reveals a visual \"early burst\" after the K-Pg extinction.\n  While mainly aimed at evolutionary analysis, this study also provides insights into the interpretability of Deep Neural Networks. We demonstrate that hierarchical semantic structures (biological taxonomy) emerged in the high-dimensional embedding space despite being trained on flat labels. Furthermore, through adversarial examples, we provide evidence that our model in this task can overcome texture bias and learn holistic shape representations (body plans), challenging the prevailing view that CNNs rely primarily on local textures."}
{"id": "2602.02620", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02620", "abs": "https://arxiv.org/abs/2602.02620", "authors": ["Weining Fu", "Kai Shu", "Kui Xu", "Qiangfeng Cliff Zhang"], "title": "CryoLVM: Self-supervised Learning from Cryo-EM Density Maps with Large Vision Models", "comment": null, "summary": "Cryo-electron microscopy (cryo-EM) has revolutionized structural biology by enabling near-atomic-level visualization of biomolecular assemblies. However, the exponential growth in cryo-EM data throughput and complexity, coupled with diverse downstream analytical tasks, necessitates unified computational frameworks that transcend current task-specific deep learning approaches with limited scalability and generalizability. We present CryoLVM, a foundation model that learns rich structural representations from experimental density maps with resolved structures by leveraging the Joint-Embedding Predictive Architecture (JEPA) integrated with SCUNet-based backbone, which can be rapidly adapted to various downstream tasks. We further introduce a novel histogram-based distribution alignment loss that accelerates convergence and enhances fine-tuning performance. We demonstrate CryoLVM's effectiveness across three critical cryo-EM tasks: density map sharpening, density map super-resolution, and missing wedge restoration. Our method consistently outperforms state-of-the-art baselines across multiple density map quality metrics, confirming its potential as a versatile model for a wide spectrum of cryo-EM applications."}
